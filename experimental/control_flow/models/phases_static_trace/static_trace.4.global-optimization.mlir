#executable_target_embedded_elf_x86_64 = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "znver3", cpu_features = "+prfchw,-cldemote,+avx,+aes,+sahf,+pclmul,-xop,+crc32,-amx-fp8,+xsaves,-avx512fp16,-usermsr,-sm4,-egpr,+sse4.1,-avx512ifma,+xsave,+sse4.2,-tsxldtrk,-sm3,-ptwrite,-widekl,-movrs,+invpcid,+64bit,+xsavec,-avx10.1-512,-avx512vpopcntdq,+cmov,-avx512vp2intersect,-avx512cd,+movbe,-avxvnniint8,-ccmp,-amx-int8,-kl,-avx10.1-256,-sha512,-avxvnni,-rtm,+adx,+avx2,-hreset,-movdiri,-serialize,+vpclmulqdq,-avx512vl,-uintr,-cf,+clflushopt,-raoint,-cmpccxadd,+bmi,-amx-tile,+sse,-avx10.2-256,-gfni,-avxvnniint16,-amx-fp16,-zu,-ndd,+xsaveopt,+rdrnd,-avx512f,-amx-bf16,-avx512bf16,-avx512vnni,-push2pop2,+cx8,-avx512bw,+sse3,+pku,-nf,-amx-tf32,-amx-avx512,+fsgsbase,+clzero,+mwaitx,-lwp,+lzcnt,+sha,-movdir64b,-ppx,+wbnoinvd,-enqcmd,-amx-transpose,-avx10.2-512,-avxneconvert,-tbm,-pconfig,-amx-complex,+ssse3,+cx16,+bmi2,+fma,+popcnt,-avxifma,+f16c,-avx512bitalg,+rdpru,+clwb,+mmx,+sse2,+rdseed,-avx512vbmi2,-prefetchi,-amx-movrs,+rdpid,-fma4,-avx512vbmi,+shstk,+vaes,-waitpkg,-sgx,+fxsr,-avx512dq,+sse4a", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128", iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver<>, max_stack_allocation_size = 32768 : i64, native_vector_size = 32 : i64, target_triple = "x86_64-unknown-unknown-eabi-elf"}>
#map = affine_map<() -> ()>
#map1 = affine_map<(d0, d1, d2) -> (d0)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map3 = affine_map<(d0, d1, d2, d3, d4, d5) -> (d3, d1 * 4 + d4, d2 * 4 + d5)>
#map4 = affine_map<(d0, d1, d2, d3, d4, d5) -> (d0, d3, d4, d5)>
#map5 = affine_map<(d0, d1, d2, d3, d4, d5) -> (d0, d1, d2)>
#map6 = affine_map<(d0, d1, d2, d3, d4) -> (d0, d1 * 2 + d3, d2 * 2 + d4)>
#map7 = affine_map<(d0, d1, d2, d3, d4) -> (d3, d4)>
#map8 = affine_map<(d0, d1, d2, d3, d4) -> (d0, d1, d2)>
#map9 = affine_map<(d0) -> (d0)>
#map10 = affine_map<(d0) -> ()>
#map11 = affine_map<(d0, d1) -> (d0, d1)>
#map12 = affine_map<(d0, d1) -> ()>
#map13 = affine_map<(d0, d1) -> (d1)>
#map14 = affine_map<(d0, d1) -> (d0)>
#device_target_local = #hal.device.target<"local", [#executable_target_embedded_elf_x86_64]> : !hal.device
module attributes {stream.affinity.default = #hal.device.affinity<@__device_0>} {
  util.global private @__device_0 = #device_target_local
  util.global private @__hoisted_tensor_1x256x8x1xf32 {stream.affinity.default = #hal.device.affinity<@__device_0>} = dense<"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tensor<1x256x8x1xf32>
  util.func public @main_graph$async(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view, %arg4: !hal.fence, %arg5: !hal.fence) -> (!hal.buffer_view, !hal.buffer_view) attributes {inlining_policy = #util.inline.never, iree.abi.model = "coarse-fences", iree.abi.stub} {
    %cst = arith.constant dense<[0.000000e+00, 0.111111112, 0.222222224, 0.333333343, 0.444444448, 0.555555582, 0.666666686, 0.777777791, 0.888888895, 1.000000e+00]> : tensor<10xf32>
    %cst_0 = arith.constant dense<[1.000000e+00, 0.888888895, 0.777777791, 0.666666627, 0.555555582, 0.444444418, 0.333333313, 0.222222209, 0.111111104, 0.000000e+00]> : tensor<10xf32>
    %cst_1 = arith.constant dense<2> : tensor<i64>
    %cst_2 = arith.constant dense<1> : tensor<i64>
    %cst_3 = arith.constant dense<0> : tensor<i64>
    %cst_4 = arith.constant dense<[0.000000e+00, -1.000000e-01]> : tensor<2xf32>
    %cst_5 = arith.constant dense<[-2.000000e-01, 0.000000e+00]> : tensor<2xf32>
    %cst_6 = arith.constant dense<1.000000e-01> : tensor<f32>
    %cst_7 = arith.constant dense<9.99999997E-7> : tensor<f32>
    %cst_8 = arith.constant dense<-1.000000e+00> : tensor<f32>
    %cst_9 = arith.constant dense<1.000000e+00> : tensor<f32>
    %cst_10 = arith.constant dense<5.000000e-01> : tensor<f32>
    %cst_11 = arith.constant dense<2.000000e+00> : tensor<f32>
    %cst_12 = arith.constant dense<9.99999974E-5> : tensor<f32>
    %cst_13 = arith.constant dense<"0xA4E062BD6F10A2BDF988443C9D175DBDC10D0BBEE2788DBD3D23A9BD501B7A3DA06B673DC090123EF900C63D2A100ABEC0E7D43D7E941CBC25580B3ECD8EBABD075D0E3EA3222C3D1ADEF53D6FAFC0BCE158683DC8F0F03BAD63CBBD0E57183DBEEE97BDDAE7F3BA769EDC3C7374EB3D4E39B33D106142BD382EA7BC892A01BEC026C63D1087BB3DA69D783D32427B3D4213F93D30DA0CBEC15A803DF17AB63D8A1A043EB867E7BDC529363D951A0CBE2FA62C3B565E043E93A9C5BC14469A3B0C6CA6BD2E66EEBD108FEDBDF4DAAA3DF64DA6BD55D2463C0EAE90BD2ECE43BD0402B7BD4844D8BC6FEF45BD8F289ABD724E2DBD35E2F53DD861BDBD345DAF3DBCD10E3E38A27F3C7362293D0C6787BD20FA3CBD035807BE2FA4EEBD66790DBCE11EA53DFADE123EB6D10C3E0BBD13BE6545C63D6335D93D3D61033E6D6313BDFDE110BE6E7C403DBF1E653BF4A2603D250A513D106844BD843DA53D1EE2823DECBBC4BD3035AFBC2A51A63D959BB63D03F5183D25A672BDE20DE33DEA84133EB5EFB1BC290708BEBC93E9BB850E793BAD14FDBDE95801BE330F883DD6C4E83DF8E2F0BD204E84BDFE1802BEC88B8A3C4F33AA3D706DA93CB7B0EF3D6DA8E9BD819AE23D24AF903DC74412BE545F0A3E52894C3D993BAC3D01D7453DAB55D03D34A2373DDDAD8CBD9FFE25BDBEF4CB3D3B399BBDE380CEBD195A2CBD5990CDBDC062AEBDBEE2E2BD96D8543D963567BC07AFE23CE3069F3D99A7013EF655EEBDE95BB5BB57B72BBD1A3AEDBD6ED50C3EA362E2BDBAE2BD3C7886133E4D0F7E3C3EA8F93CAA7AECBD0B22933BF532A0BD3CEE07BE9653ADBD3F8FA6BD9D507EBC8FF6C0BC19C801BE67E590BDA26D3FBC72EEA33D0902DE3D12F202BE97988B3D4FFB15BCD53E803DC446B9BC82C31B3D47FFD4BD581A843D8623133EE83DB6BD58094ABDDC2CE23DEDBC133E3172CE3D21125EBD29347B3D386DFBBDD03723BD11A8B4396362003ECBE981BC8A04A5BC947CC43DA4E7873DC3AFF8BC490EDF3CD3388BBDC1773B3D12F16FBDBECEE1BDB86F18BDB030243CD6E4E2BDCF2D7B3C"> : tensor<4x3x4x4xf32>
    %cst_14 = arith.constant dense<[-0.0291617829, 0.0185516253, -0.0336317755, 0.0323117375]> : tensor<4xf32>
    %cst_15 = arith.constant dense<[-0.0322122052, -0.0469594523]> : tensor<2xf32>
    %cst_16 = arith.constant 0.000000e+00 : f32
    %cst_17 = arith.constant 0xFF800000 : f32
    %cst_18 = arith.constant 1.000000e+00 : f32
    %0 = hal.tensor.import wait(%arg4) => %arg0 : !hal.buffer_view -> tensor<1x3x64x64xf32>
    %1 = hal.tensor.import wait(%arg4) => %arg1 : !hal.buffer_view -> tensor<3xf32>
    %2 = hal.tensor.import wait(%arg4) => %arg2 : !hal.buffer_view -> tensor<2xf32>
    %3 = hal.tensor.import wait(%arg4) => %arg3 : !hal.buffer_view -> tensor<2xf32>
    %4 = tensor.empty() : tensor<f32>
    %5 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %3[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%5, %cst_12 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %7 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %3[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %8 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%7, %cst_12 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %9 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%6, %8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%9, %cst_11 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.divf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %11 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%8, %6 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %12 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%11, %cst_10 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.divf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %13 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_1 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %1[%382] : tensor<3xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %14 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%12, %cst_11 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.divf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %15 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%13, %14 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %16 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %1[%382] : tensor<3xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %17 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%15 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %18 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%10, %17 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %19 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%16, %18 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %20 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %1[%382] : tensor<3xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %21 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%15 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %22 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%10, %21 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %23 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%20, %22 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %24 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%13, %12 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded = tensor.expand_shape %19 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_19 = tensor.expand_shape %23 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_20 = tensor.expand_shape %24 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat = tensor.concat dim(0) %expanded, %expanded_19, %expanded_20 : (tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<3xf32>
    %collapsed = tensor.collapse_shape %0 [[0, 1], [2], [3]] : tensor<1x3x64x64xf32> into tensor<3x64x64xf32>
    %padded = tensor.pad %collapsed low[0, 1, 1] high[0, 1, 1] {
    ^bb0(%arg6: index, %arg7: index, %arg8: index):
      tensor.yield %cst_16 : f32
    } : tensor<3x64x64xf32> to tensor<3x66x66xf32>
    %25 = tensor.empty() : tensor<4x16x16xf32>
    %26 = linalg.generic {indexing_maps = [#map1, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%cst_14 : tensor<4xf32>) outs(%25 : tensor<4x16x16xf32>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    } -> tensor<4x16x16xf32>
    %27 = linalg.fill ins(%cst_16 : f32) outs(%25 : tensor<4x16x16xf32>) -> tensor<4x16x16xf32>
    %28 = linalg.generic {indexing_maps = [#map3, #map4, #map5], iterator_types = ["parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%padded, %cst_13 : tensor<3x66x66xf32>, tensor<4x3x4x4xf32>) outs(%27 : tensor<4x16x16xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      %383 = arith.addf %out, %382 : f32
      linalg.yield %383 : f32
    } -> tensor<4x16x16xf32>
    %29 = linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%28, %26 : tensor<4x16x16xf32>, tensor<4x16x16xf32>) outs(%27 : tensor<4x16x16xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<4x16x16xf32>
    %30 = linalg.generic {indexing_maps = [#map2, #map2], iterator_types = ["parallel", "parallel", "parallel"]} ins(%29 : tensor<4x16x16xf32>) outs(%25 : tensor<4x16x16xf32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf ugt, %in, %cst_16 : f32
      %383 = arith.select %382, %in, %cst_16 : f32
      linalg.yield %383 : f32
    } -> tensor<4x16x16xf32>
    %31 = tensor.empty() : tensor<2x2xf32>
    %32 = tensor.empty() : tensor<4x8x8xf32>
    %33 = linalg.fill ins(%cst_17 : f32) outs(%32 : tensor<4x8x8xf32>) -> tensor<4x8x8xf32>
    %34 = linalg.generic {indexing_maps = [#map6, #map7, #map8], iterator_types = ["parallel", "parallel", "parallel", "reduction", "reduction"]} ins(%30, %31 : tensor<4x16x16xf32>, tensor<2x2xf32>) outs(%33 : tensor<4x8x8xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.maximumf %out, %in : f32
      linalg.yield %382 : f32
    } -> tensor<4x8x8xf32>
    %expanded_21 = tensor.expand_shape %34 [[0, 1], [2], [3]] output_shape [1, 4, 8, 8] : tensor<4x8x8xf32> into tensor<1x4x8x8xf32>
    %collapsed_22 = tensor.collapse_shape %expanded_21 [[0], [1, 2, 3]] : tensor<1x4x8x8xf32> into tensor<1x256xf32>
    %expanded_23 = tensor.expand_shape %collapsed_22 [[0], [1, 2, 3]] output_shape [1, 256, 1, 1] : tensor<1x256xf32> into tensor<1x256x1x1xf32>
    %__hoisted_tensor_1x256x8x1xf32 = util.global.load immutable @__hoisted_tensor_1x256x8x1xf32 : tensor<1x256x8x1xf32>
    %35 = tensor.empty() : tensor<1x1x1x8xf32>
    %36 = linalg.fill ins(%cst_16 : f32) outs(%35 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %37 = linalg.mmt4d ins(%expanded_23, %__hoisted_tensor_1x256x8x1xf32 : tensor<1x256x1x1xf32>, tensor<1x256x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %38 = tensor.empty() : tensor<1x2xf32>
    %unpack = linalg.unpack %37 outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [1, 8] into %38 : tensor<1x1x1x8xf32> -> tensor<1x2xf32>
    %collapsed_24 = tensor.collapse_shape %unpack [[0, 1]] : tensor<1x2xf32> into tensor<2xf32>
    %39 = tensor.empty() : tensor<2xf32>
    %40 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%collapsed_24, %cst_15 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %41 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %2[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %42 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %2[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %43 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%41 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %44 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%43, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %45 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%41, %42 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %46 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%45 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %47 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%46, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %48 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%44, %47 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %49 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%41 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %50 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%49, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %51 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%45 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %52 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%51, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %53 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%50, %52 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_25 = tensor.expand_shape %48 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_26 = tensor.expand_shape %53 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_27 = tensor.concat dim(0) %expanded_25, %expanded_26 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %54 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_27 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %55 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%49, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %56 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%55, %52 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %57 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%51, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_28 = tensor.expand_shape %56 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_29 = tensor.expand_shape %57 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_30 = tensor.concat dim(0) %expanded_28, %expanded_29 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_31 = tensor.expand_shape %47 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_32 = tensor.concat dim(0) %expanded_25, %expanded_31 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_33 = tensor.expand_shape %concat_30 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_34 = tensor.expand_shape %concat_32 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_35 = tensor.concat dim(0) %expanded_33, %expanded_34 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %58 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_35[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %59 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %58[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_36 = tensor.expand_shape %59 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %60 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_35[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %61 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %60[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_37 = tensor.expand_shape %61 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %62 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%59, %61 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %63 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %58[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %64 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %60[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %65 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%63, %64 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %66 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%62, %65 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %67 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%66, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %68 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%67 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %69 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%68, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %70 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%63 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_38 = tensor.expand_shape %70 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_39 = tensor.concat dim(0) %expanded_37, %expanded_38 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %71 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%64 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_40 = tensor.expand_shape %71 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_41 = tensor.concat dim(0) %expanded_40, %expanded_36 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_42 = tensor.expand_shape %concat_39 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_43 = tensor.expand_shape %concat_41 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_44 = tensor.concat dim(0) %expanded_42, %expanded_43 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %72 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_44, %69 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %73 = tensor.empty() : tensor<1x2x8x1xf32>
    %pack = linalg.pack %72 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_45 = tensor.expand_shape %54 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %74 = linalg.mmt4d ins(%expanded_45, %pack : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_46 = tensor.collapse_shape %74 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_47 = linalg.unpack %collapsed_46 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %75 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_47, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %76 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%2, %75 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %77 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %76[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %78 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %76[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %79 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%77 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %80 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%79, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %81 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%77, %78 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %82 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%81 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %83 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%82, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %84 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%80, %83 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %85 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%77 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %86 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%85, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %87 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%81 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %88 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%87, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %89 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%86, %88 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_48 = tensor.expand_shape %84 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_49 = tensor.expand_shape %89 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_50 = tensor.concat dim(0) %expanded_48, %expanded_49 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %90 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_50 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %91 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%85, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %92 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%91, %88 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %93 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%87, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_51 = tensor.expand_shape %92 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_52 = tensor.expand_shape %93 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_53 = tensor.concat dim(0) %expanded_51, %expanded_52 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_54 = tensor.expand_shape %83 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_55 = tensor.concat dim(0) %expanded_48, %expanded_54 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_56 = tensor.expand_shape %concat_53 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_57 = tensor.expand_shape %concat_55 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_58 = tensor.concat dim(0) %expanded_56, %expanded_57 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %94 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_58[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %95 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %94[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_59 = tensor.expand_shape %95 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %96 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_58[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %97 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %96[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_60 = tensor.expand_shape %97 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %98 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%95, %97 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %99 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %94[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %100 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %96[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %101 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%99, %100 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %102 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%98, %101 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %103 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%102, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %104 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%103 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %105 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%104, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %106 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%99 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_61 = tensor.expand_shape %106 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_62 = tensor.concat dim(0) %expanded_60, %expanded_61 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %107 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%100 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_63 = tensor.expand_shape %107 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_64 = tensor.concat dim(0) %expanded_63, %expanded_59 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_65 = tensor.expand_shape %concat_62 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_66 = tensor.expand_shape %concat_64 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_67 = tensor.concat dim(0) %expanded_65, %expanded_66 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %108 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_67, %105 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %pack_68 = linalg.pack %108 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_69 = tensor.expand_shape %90 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %109 = linalg.mmt4d ins(%expanded_69, %pack_68 : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_70 = tensor.collapse_shape %109 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_71 = linalg.unpack %collapsed_70 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %110 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_71, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %111 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%76, %110 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %112 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %111[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %113 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %111[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %114 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%112 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %115 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%114, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %116 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%112, %113 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %117 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%116 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %118 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%117, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %119 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%115, %118 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %120 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%112 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %121 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%120, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %122 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%116 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %123 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%122, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %124 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%121, %123 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_72 = tensor.expand_shape %119 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_73 = tensor.expand_shape %124 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_74 = tensor.concat dim(0) %expanded_72, %expanded_73 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %125 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_74 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %126 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%120, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %127 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%126, %123 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %128 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%122, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_75 = tensor.expand_shape %127 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_76 = tensor.expand_shape %128 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_77 = tensor.concat dim(0) %expanded_75, %expanded_76 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_78 = tensor.expand_shape %118 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_79 = tensor.concat dim(0) %expanded_72, %expanded_78 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_80 = tensor.expand_shape %concat_77 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_81 = tensor.expand_shape %concat_79 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_82 = tensor.concat dim(0) %expanded_80, %expanded_81 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %129 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_82[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %130 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %129[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_83 = tensor.expand_shape %130 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %131 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_82[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %132 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %131[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_84 = tensor.expand_shape %132 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %133 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%130, %132 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %134 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %129[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %135 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %131[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %136 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%134, %135 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %137 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%133, %136 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %138 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%137, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %139 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%138 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %140 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%139, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %141 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%134 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_85 = tensor.expand_shape %141 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_86 = tensor.concat dim(0) %expanded_84, %expanded_85 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %142 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%135 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_87 = tensor.expand_shape %142 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_88 = tensor.concat dim(0) %expanded_87, %expanded_83 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_89 = tensor.expand_shape %concat_86 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_90 = tensor.expand_shape %concat_88 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_91 = tensor.concat dim(0) %expanded_89, %expanded_90 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %143 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_91, %140 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %pack_92 = linalg.pack %143 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_93 = tensor.expand_shape %125 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %144 = linalg.mmt4d ins(%expanded_93, %pack_92 : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_94 = tensor.collapse_shape %144 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_95 = linalg.unpack %collapsed_94 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %145 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_95, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %146 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%111, %145 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %147 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %146[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %148 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %146[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %149 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%147 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %150 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%149, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %151 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%147, %148 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %152 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%151 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %153 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%152, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %154 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%150, %153 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %155 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%147 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %156 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%155, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %157 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%151 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %158 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%157, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %159 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%156, %158 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_96 = tensor.expand_shape %154 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_97 = tensor.expand_shape %159 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_98 = tensor.concat dim(0) %expanded_96, %expanded_97 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %160 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_98 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %161 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%155, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %162 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%161, %158 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %163 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%157, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_99 = tensor.expand_shape %162 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_100 = tensor.expand_shape %163 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_101 = tensor.concat dim(0) %expanded_99, %expanded_100 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_102 = tensor.expand_shape %153 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_103 = tensor.concat dim(0) %expanded_96, %expanded_102 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_104 = tensor.expand_shape %concat_101 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_105 = tensor.expand_shape %concat_103 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_106 = tensor.concat dim(0) %expanded_104, %expanded_105 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %164 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_106[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %165 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %164[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_107 = tensor.expand_shape %165 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %166 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_106[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %167 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %166[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_108 = tensor.expand_shape %167 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %168 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%165, %167 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %169 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %164[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %170 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %166[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %171 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%169, %170 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %172 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%168, %171 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %173 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%172, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %174 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%173 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %175 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%174, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %176 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%169 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_109 = tensor.expand_shape %176 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_110 = tensor.concat dim(0) %expanded_108, %expanded_109 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %177 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%170 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_111 = tensor.expand_shape %177 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_112 = tensor.concat dim(0) %expanded_111, %expanded_107 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_113 = tensor.expand_shape %concat_110 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_114 = tensor.expand_shape %concat_112 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_115 = tensor.concat dim(0) %expanded_113, %expanded_114 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %178 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_115, %175 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %pack_116 = linalg.pack %178 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_117 = tensor.expand_shape %160 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %179 = linalg.mmt4d ins(%expanded_117, %pack_116 : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_118 = tensor.collapse_shape %179 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_119 = linalg.unpack %collapsed_118 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %180 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_119, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %181 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%146, %180 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %182 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %181[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %183 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %181[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %184 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%182 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %185 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%184, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %186 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%182, %183 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %187 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%186 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %188 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%187, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %189 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%185, %188 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %190 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%182 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %191 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%190, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %192 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%186 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %193 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%192, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %194 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%191, %193 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_120 = tensor.expand_shape %189 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_121 = tensor.expand_shape %194 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_122 = tensor.concat dim(0) %expanded_120, %expanded_121 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %195 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_122 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %196 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%190, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %197 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%196, %193 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %198 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%192, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_123 = tensor.expand_shape %197 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_124 = tensor.expand_shape %198 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_125 = tensor.concat dim(0) %expanded_123, %expanded_124 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_126 = tensor.expand_shape %188 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_127 = tensor.concat dim(0) %expanded_120, %expanded_126 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_128 = tensor.expand_shape %concat_125 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_129 = tensor.expand_shape %concat_127 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_130 = tensor.concat dim(0) %expanded_128, %expanded_129 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %199 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_130[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %200 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %199[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_131 = tensor.expand_shape %200 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %201 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_130[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %202 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %201[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_132 = tensor.expand_shape %202 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %203 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%200, %202 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %204 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %199[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %205 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %201[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %206 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%204, %205 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %207 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%203, %206 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %208 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%207, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %209 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%208 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %210 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%209, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %211 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%204 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_133 = tensor.expand_shape %211 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_134 = tensor.concat dim(0) %expanded_132, %expanded_133 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %212 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%205 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_135 = tensor.expand_shape %212 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_136 = tensor.concat dim(0) %expanded_135, %expanded_131 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_137 = tensor.expand_shape %concat_134 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_138 = tensor.expand_shape %concat_136 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_139 = tensor.concat dim(0) %expanded_137, %expanded_138 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %213 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_139, %210 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %pack_140 = linalg.pack %213 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_141 = tensor.expand_shape %195 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %214 = linalg.mmt4d ins(%expanded_141, %pack_140 : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_142 = tensor.collapse_shape %214 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_143 = linalg.unpack %collapsed_142 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %215 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_143, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %216 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%181, %215 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %217 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %216[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %218 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %216[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %219 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%217 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %220 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%219, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %221 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%217, %218 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %222 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%221 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %223 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%222, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %224 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%220, %223 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %225 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%217 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %226 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%225, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %227 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%221 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %228 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%227, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %229 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%226, %228 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_144 = tensor.expand_shape %224 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_145 = tensor.expand_shape %229 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_146 = tensor.concat dim(0) %expanded_144, %expanded_145 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %230 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_146 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %231 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%225, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %232 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%231, %228 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %233 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%227, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_147 = tensor.expand_shape %232 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_148 = tensor.expand_shape %233 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_149 = tensor.concat dim(0) %expanded_147, %expanded_148 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_150 = tensor.expand_shape %223 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_151 = tensor.concat dim(0) %expanded_144, %expanded_150 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_152 = tensor.expand_shape %concat_149 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_153 = tensor.expand_shape %concat_151 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_154 = tensor.concat dim(0) %expanded_152, %expanded_153 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %234 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_154[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %235 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %234[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_155 = tensor.expand_shape %235 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %236 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_154[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %237 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %236[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_156 = tensor.expand_shape %237 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %238 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%235, %237 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %239 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %234[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %240 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %236[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %241 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%239, %240 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %242 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%238, %241 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %243 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%242, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %244 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%243 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %245 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%244, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %246 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%239 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_157 = tensor.expand_shape %246 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_158 = tensor.concat dim(0) %expanded_156, %expanded_157 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %247 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%240 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_159 = tensor.expand_shape %247 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_160 = tensor.concat dim(0) %expanded_159, %expanded_155 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_161 = tensor.expand_shape %concat_158 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_162 = tensor.expand_shape %concat_160 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_163 = tensor.concat dim(0) %expanded_161, %expanded_162 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %248 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_163, %245 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %pack_164 = linalg.pack %248 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_165 = tensor.expand_shape %230 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %249 = linalg.mmt4d ins(%expanded_165, %pack_164 : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_166 = tensor.collapse_shape %249 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_167 = linalg.unpack %collapsed_166 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %250 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_167, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %251 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%216, %250 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %252 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %251[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %253 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %251[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %254 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%252 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %255 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%254, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %256 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%252, %253 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %257 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%256 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %258 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%257, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %259 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%255, %258 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %260 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%252 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %261 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%260, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %262 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%256 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %263 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%262, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %264 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%261, %263 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_168 = tensor.expand_shape %259 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_169 = tensor.expand_shape %264 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_170 = tensor.concat dim(0) %expanded_168, %expanded_169 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %265 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_170 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %266 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%260, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %267 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%266, %263 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %268 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%262, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_171 = tensor.expand_shape %267 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_172 = tensor.expand_shape %268 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_173 = tensor.concat dim(0) %expanded_171, %expanded_172 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_174 = tensor.expand_shape %258 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_175 = tensor.concat dim(0) %expanded_168, %expanded_174 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_176 = tensor.expand_shape %concat_173 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_177 = tensor.expand_shape %concat_175 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_178 = tensor.concat dim(0) %expanded_176, %expanded_177 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %269 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_178[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %270 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %269[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_179 = tensor.expand_shape %270 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %271 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_178[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %272 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %271[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_180 = tensor.expand_shape %272 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %273 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%270, %272 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %274 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %269[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %275 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %271[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %276 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%274, %275 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %277 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%273, %276 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %278 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%277, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %279 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%278 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %280 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%279, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %281 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%274 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_181 = tensor.expand_shape %281 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_182 = tensor.concat dim(0) %expanded_180, %expanded_181 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %282 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%275 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_183 = tensor.expand_shape %282 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_184 = tensor.concat dim(0) %expanded_183, %expanded_179 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_185 = tensor.expand_shape %concat_182 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_186 = tensor.expand_shape %concat_184 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_187 = tensor.concat dim(0) %expanded_185, %expanded_186 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %283 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_187, %280 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %pack_188 = linalg.pack %283 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_189 = tensor.expand_shape %265 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %284 = linalg.mmt4d ins(%expanded_189, %pack_188 : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_190 = tensor.collapse_shape %284 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_191 = linalg.unpack %collapsed_190 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %285 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_191, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %286 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%251, %285 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %287 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %286[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %288 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %286[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %289 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%287 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %290 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%289, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %291 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%287, %288 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %292 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%291 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %293 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%292, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %294 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%290, %293 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %295 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%287 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %296 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%295, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %297 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%291 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %298 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%297, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %299 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%296, %298 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_192 = tensor.expand_shape %294 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_193 = tensor.expand_shape %299 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_194 = tensor.concat dim(0) %expanded_192, %expanded_193 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %300 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_194 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %301 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%295, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %302 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%301, %298 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %303 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%297, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_195 = tensor.expand_shape %302 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_196 = tensor.expand_shape %303 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_197 = tensor.concat dim(0) %expanded_195, %expanded_196 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_198 = tensor.expand_shape %293 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_199 = tensor.concat dim(0) %expanded_192, %expanded_198 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_200 = tensor.expand_shape %concat_197 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_201 = tensor.expand_shape %concat_199 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_202 = tensor.concat dim(0) %expanded_200, %expanded_201 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %304 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_202[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %305 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %304[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_203 = tensor.expand_shape %305 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %306 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_202[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %307 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %306[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_204 = tensor.expand_shape %307 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %308 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%305, %307 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %309 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %304[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %310 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %306[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %311 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%309, %310 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %312 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%308, %311 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %313 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%312, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %314 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%313 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %315 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%314, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %316 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%309 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_205 = tensor.expand_shape %316 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_206 = tensor.concat dim(0) %expanded_204, %expanded_205 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %317 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%310 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_207 = tensor.expand_shape %317 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_208 = tensor.concat dim(0) %expanded_207, %expanded_203 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_209 = tensor.expand_shape %concat_206 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_210 = tensor.expand_shape %concat_208 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_211 = tensor.concat dim(0) %expanded_209, %expanded_210 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %318 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_211, %315 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %pack_212 = linalg.pack %318 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_213 = tensor.expand_shape %300 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %319 = linalg.mmt4d ins(%expanded_213, %pack_212 : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_214 = tensor.collapse_shape %319 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_215 = linalg.unpack %collapsed_214 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %320 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_215, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %321 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%286, %320 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %322 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %321[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %323 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %321[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %324 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%322 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %325 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%324, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %326 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%322, %323 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %327 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%326 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %328 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%327, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %329 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%325, %328 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %330 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%322 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %331 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%330, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %332 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%326 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %333 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%332, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %334 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%331, %333 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_216 = tensor.expand_shape %329 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_217 = tensor.expand_shape %334 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_218 = tensor.concat dim(0) %expanded_216, %expanded_217 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %335 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%40, %concat_218 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %336 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%330, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %337 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%336, %333 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %338 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%332, %cst_8 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_219 = tensor.expand_shape %337 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_220 = tensor.expand_shape %338 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_221 = tensor.concat dim(0) %expanded_219, %expanded_220 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_222 = tensor.expand_shape %328 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_223 = tensor.concat dim(0) %expanded_216, %expanded_222 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_224 = tensor.expand_shape %concat_221 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_225 = tensor.expand_shape %concat_223 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_226 = tensor.concat dim(0) %expanded_224, %expanded_225 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %339 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_3 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_226[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %340 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %339[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_227 = tensor.expand_shape %340 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %341 = linalg.generic {indexing_maps = [#map10, #map9], iterator_types = ["parallel"]} ins(%cst_2 : tensor<i64>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %383 = linalg.index 0 : index
      %extracted = tensor.extract %concat_226[%382, %383] : tensor<2x2xf32>
      linalg.yield %extracted : f32
    } -> tensor<2xf32>
    %342 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %341[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %expanded_228 = tensor.expand_shape %342 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %343 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%340, %342 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %344 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %339[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %345 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %341[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %346 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%344, %345 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %347 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%343, %346 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.subf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %348 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%347, %cst_7 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %349 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%348 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.cmpf one, %in, %cst_16 : f32
      cf.assert %382, "unimplemented: tensor with zero element"
      %383 = arith.divf %cst_18, %in : f32
      linalg.yield %383 : f32
    } -> tensor<f32>
    %350 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%349, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %351 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%344 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_229 = tensor.expand_shape %351 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_230 = tensor.concat dim(0) %expanded_228, %expanded_229 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %352 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%345 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = arith.negf %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_231 = tensor.expand_shape %352 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_232 = tensor.concat dim(0) %expanded_231, %expanded_227 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %expanded_233 = tensor.expand_shape %concat_230 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %expanded_234 = tensor.expand_shape %concat_232 [[0, 1]] output_shape [1, 2] : tensor<2xf32> into tensor<1x2xf32>
    %concat_235 = tensor.concat dim(0) %expanded_233, %expanded_234 : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<2x2xf32>
    %353 = linalg.generic {indexing_maps = [#map11, #map12, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_235, %350 : tensor<2x2xf32>, tensor<f32>) outs(%31 : tensor<2x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2x2xf32>
    %pack_236 = linalg.pack %353 padding_value(%cst_16 : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [8, 1] into %73 : tensor<2x2xf32> -> tensor<1x2x8x1xf32>
    %expanded_237 = tensor.expand_shape %335 [[0, 1, 2, 3]] output_shape [1, 2, 1, 1] : tensor<2xf32> into tensor<1x2x1x1xf32>
    %354 = linalg.mmt4d ins(%expanded_237, %pack_236 : tensor<1x2x1x1xf32>, tensor<1x2x8x1xf32>) outs(%36 : tensor<1x1x1x8xf32>) -> tensor<1x1x1x8xf32>
    %collapsed_238 = tensor.collapse_shape %354 [[0, 1], [2, 3]] : tensor<1x1x1x8xf32> into tensor<1x8xf32>
    %unpack_239 = linalg.unpack %collapsed_238 outer_dims_perm = [0] inner_dims_pos = [0] inner_tiles = [8] into %39 : tensor<1x8xf32> -> tensor<2xf32>
    %355 = linalg.generic {indexing_maps = [#map9, #map10, #map9], iterator_types = ["parallel"]} ins(%unpack_239, %cst_6 : tensor<2xf32>, tensor<f32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %356 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%321, %355 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %357 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_3 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %356[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %358 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%cst_2 : tensor<i64>) outs(%4 : tensor<f32>) {
    ^bb0(%in: i64, %out: f32):
      %382 = arith.index_cast %in : i64 to index
      %extracted = tensor.extract %356[%382] : tensor<2xf32>
      linalg.yield %extracted : f32
    } -> tensor<f32>
    %359 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%357 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %360 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%359, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %361 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%357, %358 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %362 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%361 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.cos %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %363 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%362, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %364 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%360, %363 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %365 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%357 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %366 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%365, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %367 = linalg.generic {indexing_maps = [#map, #map], iterator_types = []} ins(%361 : tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %out: f32):
      %382 = math.sin %in : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %368 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%367, %cst_9 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %369 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = []} ins(%366, %368 : tensor<f32>, tensor<f32>) outs(%4 : tensor<f32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<f32>
    %expanded_240 = tensor.expand_shape %364 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %expanded_241 = tensor.expand_shape %369 [] output_shape [1] : tensor<f32> into tensor<1xf32>
    %concat_242 = tensor.concat dim(0) %expanded_240, %expanded_241 : (tensor<1xf32>, tensor<1xf32>) -> tensor<2xf32>
    %370 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%concat_242, %cst_5 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %371 = linalg.generic {indexing_maps = [#map9, #map9, #map9], iterator_types = ["parallel"]} ins(%370, %cst_4 : tensor<2xf32>, tensor<2xf32>) outs(%39 : tensor<2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<2xf32>
    %372 = tensor.empty() : tensor<10x2xf32>
    %373 = linalg.generic {indexing_maps = [#map13, #map14, #map11], iterator_types = ["parallel", "parallel"]} ins(%concat_242, %cst_0 : tensor<2xf32>, tensor<10xf32>) outs(%372 : tensor<10x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<10x2xf32>
    %374 = linalg.generic {indexing_maps = [#map13, #map14, #map11], iterator_types = ["parallel", "parallel"]} ins(%370, %cst : tensor<2xf32>, tensor<10xf32>) outs(%372 : tensor<10x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<10x2xf32>
    %375 = linalg.generic {indexing_maps = [#map11, #map11, #map11], iterator_types = ["parallel", "parallel"]} ins(%373, %374 : tensor<10x2xf32>, tensor<10x2xf32>) outs(%372 : tensor<10x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<10x2xf32>
    %376 = linalg.generic {indexing_maps = [#map13, #map14, #map11], iterator_types = ["parallel", "parallel"]} ins(%370, %cst_0 : tensor<2xf32>, tensor<10xf32>) outs(%372 : tensor<10x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<10x2xf32>
    %377 = linalg.generic {indexing_maps = [#map13, #map14, #map11], iterator_types = ["parallel", "parallel"]} ins(%371, %cst : tensor<2xf32>, tensor<10xf32>) outs(%372 : tensor<10x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.mulf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<10x2xf32>
    %378 = linalg.generic {indexing_maps = [#map11, #map11, #map11], iterator_types = ["parallel", "parallel"]} ins(%376, %377 : tensor<10x2xf32>, tensor<10x2xf32>) outs(%372 : tensor<10x2xf32>) {
    ^bb0(%in: f32, %in_244: f32, %out: f32):
      %382 = arith.addf %in, %in_244 : f32
      linalg.yield %382 : f32
    } -> tensor<10x2xf32>
    %extracted_slice = tensor.extract_slice %378[1, 0] [9, 2] [1, 1] : tensor<10x2xf32> to tensor<9x2xf32>
    %concat_243 = tensor.concat dim(0) %375, %extracted_slice : (tensor<10x2xf32>, tensor<9x2xf32>) -> tensor<19x2xf32>
    %379:2 = hal.tensor.barrier join(%concat_243, %concat : tensor<19x2xf32>, tensor<3xf32>) => %arg5 : !hal.fence
    %380 = hal.tensor.export %379#0 : tensor<19x2xf32> -> !hal.buffer_view
    %381 = hal.tensor.export %379#1 : tensor<3xf32> -> !hal.buffer_view
    util.return %380, %381 : !hal.buffer_view, !hal.buffer_view
  }
  util.func public @main_graph(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view, %arg3: !hal.buffer_view) -> (!hal.buffer_view, !hal.buffer_view) attributes {iree.abi.stub} {
    %0 = util.null : !hal.fence
    %c-1_i32 = arith.constant -1 : i32
    %c0 = arith.constant 0 : index
    %device_0 = hal.devices.get %c0 : !hal.device
    %fence = hal.fence.create device(%device_0 : !hal.device) flags("None") : !hal.fence
    %1:2 = util.call @main_graph$async(%arg0, %arg1, %arg2, %arg3, %0, %fence) : (!hal.buffer_view, !hal.buffer_view, !hal.buffer_view, !hal.buffer_view, !hal.fence, !hal.fence) -> (!hal.buffer_view, !hal.buffer_view)
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) flags("None") : i32
    util.return %1#0, %1#1 : !hal.buffer_view, !hal.buffer_view
  }
}
